<html>
<head>
<title>e-Portfolio for Intelligent Agents course Summer 2024</title>
</head>

<body style="background-color: ffffbb; margin-left: 50px; margin-right: 50px;">
<h1>e-Portfolio for Intelligent Agents course Summer 2024</h1>
<h2>Chris Butterworth</h2>
<!-- <p><a href="about-me.html">About me</a></p> -->
<p><a href="https://butterworthc.github.io/ml-course/about-me.html">About me</a></p>
<p><a href="prep.html">Preparation for Intelligent Agents module</a></p>

<p>GitHub-hosted version: <a href="https://butterworthc.github.io/IntelligentAgents/e-Portfolio.html">butterworthc.github.io/IntelligentAgents/e-Portfolio.html</a></p>
<p>Online repository, showing commit descriptions: <a href="https://github.com/ButterworthC/IntelligentAgents">https://github.com/ButterworthC/IntelligentAgents</a></p>

<h3>Unit 1: Introduction to Agent-Based Computing</h3>
<p><b>Unit 1 Lecturecast</b></p>
<p>I had already read the first chapter of our textbook (<a href="#wooldridge">Wooldridge, 2009</a>) when I saw this, and noticed that it was
the source for most of the lecturecast material. However, the lecturecast was a more concise and memorable presentation of the material.</p>
<p><b>Unit 1 Readings</b></p>
<p><a href="#wooldridge">Wooldridge (2009)</a> Chapter 2: "Intelligent Agents" defines an agent as "a computer system that is <i>situated</i>
in some <i>environment</i>, and that is capable of <i>autonomous action</i> in this environment in order to meet its delegated objectives."
An ethical angle emerges on page 23 in a discussion of the factors which would trigger human intervention, one of which is:
"when the decision might cause harm." This reminded me of Asimov's Three Laws of Robotics, the first of which states:
"A robot may not injure a human being, or, through inaction, allow a human being to come to harm" (<a href="#asimov">Asimov, 1942</a>).
Wooldridge goes on to describe types of environments and agents and their capabilities, comparing agents with objects and expert systems.
Inputs, outputs and state are described, along with utility and the use of predicate functions.  It is a good, wide-ranging introduction.</p>

<h3>Unit 2: Introducing First Order Logic</h3>
<p>As described on my "preparation" page linked to above, I read about FOL in the two books shown, and watched a series of videos on the subject.
The concepts are not very difficult to understand but it can sometimes take a long time to turn a convoluted expression into an English sentence.
The biggest problem is the choice of symbols - some of the operators are in very obscure characters and 
some are not included with Microsoft Word&trade;.</p>
<p><b>Unit 2 Readings</b></p>
<p>The prescribed reading for this unit was <a href=#russell">Russell &amp; Norvig (2022)</a> Chapter 8: "First-Order Logic" 
but I found it useful to read Chapter 2: "Intelligent Agents" before this, as it had sections on rationality and
the structures of different types of agent, introducing representation and the relationships between entities.
I think I will be coming back to Chapter 8 quite often (and the sources mentioned above) to refresh my understanding of FOL in agents.</p>

<h3>Unit 3: Agent Architectures</h3>
<p><b>Unit 3 Lecturecast</b></p>
<p>This explains that agents consist of software and "architecture", of which it gives definitions from <a href="#maes">Maes (1991)</a> and 
<a href="#kaelbling">Kaelbling (1991)</a>, both of which are examined in the readings for this unit. There are sections on representation, 
reasoning and ontology, and an introduction to Brooks Behavioural Language.</p>
<p><b>Unit 3 Readings</b></p>
<p><a href="#maes">Maes (1991)</a> described systems of agents with different but interchangeable roles, 
with the ability to adjust their own importance to particular tasks.</p>
<p><a href="#kaelbling">Kaelbling (1991)</a> is about "the information content of the internal states of a machine."
One sentence that caught my eye on the first page was:
"the world may change during the computation, 
invalidating the initial semantic interpretation of the inputs, 
and possibly, therefore, the interpretation of the outputs."  So these agents need to be quick.  
Emphasis is put on the modular architecture and the incremental nature of software development.
It is made clear that this system is suitable for dynamic environments.
A distinction is made between dynamic data, which needs to be kept in individual machines,
and static data, which only needs to be in one instance, thereby reducing computing requirements.
Reference is made to <a href="#brooks">Brooks (1991)</a>, which is also in this week's reading list.</p>
<p><a href="#bratman">Bratman (1988)</a> discusses a combination of the weighing of alternatives, as in <a href="#maes">Maes (1991)</a>,
and "means-end reasoning," while bearing in mind "resource boundedness," which apparently means that agents:
"are unable to perform arbitrarily large computations in constant time."  
This recognises the problem I saw in <a href="#kaelbling">Kaelbling (1991)</a>, about getting out of synch with the state of environment,
although a footnote on page 5 says that applying these systems to real-time situations was a relatively recent idea.
The paper goes on to describe how a planning function could reduce the computing requirement by limiting the necessary reasoning.
It sounds to me analogous to the shortcutting of an AND statement when the first argument evaluates to FALSE and the second argument is not evaluated.
Also, knowledge is also bounded so that machines "are neither prescient nor omniscient."
This bounding takes the form of filtering, e.g. by time frame, location or compatibility with existing plans.</p>
<p><a href="#brooks">Brooks (1991)</a> got me in a tangle over the year to include in the citation. This paper was received by <i>Artificial Intelligence</i>
in 1987 but not printed for four years, hence the year 1991 is cited. Perhaps this means that many papers are actually older than they seem.
This paper is about agents ("independent and parallel activity producers") that interface to the environment more than to each other.
There is an interesting declaration on the first page: "No one talks about replicating the full gamut of human intelligence any more. 
Instead we see a retreat into specialized subproblems." 
That may have been true in 1987 but today all those elements are being brought together again (<a href="#goertzel">Goertzel &amp; Pennachin, 2007</a>).
Brooks advocates an incremental approach, starting with fairly simple systems. He is effectively saying we have to walk before we can run.
By "no representation" Brooks is saying a system can make decisions by 
"using the world as its own model and to continuously match the preconditions of each goal against the real world."
I found this paper to be perhaps more optimistic than realistic, but that may be because I do not fully understand the mechanisms at work.</p>
<p>Finally, <a href="#reynolds">Reynolds (1987)</a> discusses computer animation of a flock of birds, where 
"the aggregate motion of the simulated flock is the result of the dense interaction of the relatively simple behaviors of the individual simulated birds."
It is a similar problem to those in the first four papers. For these "boids" (simulated birds), three behaviours are identified: "collision avoidance..., 
velocity matching... and flock centering."  As with the other papers, computing is in LISP.</p>

<h3>Collaborative Discussion 1: Agent Based Systems</h3>
<p></p>

<h3>Unit 4: Hybrid Agent Architectures</h3>
<p><b>Unit 4 Reading</b></p>
<p>The prescribed passage was <a href="#wooldridge">Wooldridge (2009)</a> Section 5.2, titled "Hybrid Agents," but I read the whole of Chapter 5.
This included a section on reactive agents, and much material from the papers read in Unit 4 was summarised there. 
Hybrid agents combine at least two layers such as proactive and reasoning or planning layers, which can work either in parallel 
(where each is connected to sensor input and effector output) or series (where the inputs and outputs are connected to interface layers and the proactive 
and reasoning layers pass control to each other).  Other layers can include modelling layers, cooperation layers etc.
Four examples are given: TouringMachines, InterRRaP, 3T and Stanley, a self-driving Volkswagen.</p>

<h3>Unit 5: Agent Communication</h3>
<p><b>Unit 5 Lecturecast</b></p>
<p>This goes into the ontologies of agentsa, and their alignment.  It is based on the readings for this unit 
but also goes into knowledge query and manipulation language (KQML) and the knowledge interchange format (KIF).</p>

<p><b>Unit 5 Readings</b></p>
<p><a href="#searle">Searle (1969)</a> begins by asking simple questions about words and meaning, building up to the philosophy of language,
which he is keen to distance from "linguistic philosophy." 
He soon starts defining obscure terms: "Synonymy is defined as: two words are synonymous if and only if they have the same meaning; 
and analyticity is defined as: a statement is analytic if and only if it is true in virtue of its meaning or by definition."
Then he states the need for "some objective test for analyticity and synonymy."
Searle gives the impression of an eccentric with a lot of time on his hands, digging ever deeper into these concepts and the meaning of "meaning."
He even cites <a href="#wittgenstein">Wittgenstein (1953)</a> as pointing out that "exactness is relative to some purpose."
Searle seems to think that the inclusion of many examples will clarify the linguistic problems he describes but I think they obscure them.
By Chapter 2, Searle has formulated "that speaking a language is engaging in a rule-governed form of behavior..., performing acts according to rules"
and here he defines "different kinds of speech acts..., propositions, rules, meaning, and facts."
He explains that speech acts consist of utterance acts, propositional acts, illocutionary acts and perlocutionary acts.
I avoided learning his symbolism to prevent confusion with the symbolism of first order logic.
I was glad of the opportunity to learn new words such as <i>idiolect</i>, <i>illocution</i> and <i>perlocution</i>, 
but I found this to be a very turgid book and am pleased to see it does not reappear in the reading lists for future units in this module.</p>
<p><a href="#payne">Payne (2014)</a> discusses solutions to the problem of different agents having different ontologies and even vocabularies.
Possible solutions include giving agents access to a mapped list of equivalent terms 
and letting agents exchange messages until they develop some knowledge of their ontological differences.
The authors introduce their idea of "the Correspondence Inclusion Dialogue (CID), whereby agents negotiate by exchanging beliefs of the utilities 
of each correspondence."  
They are thus able to align their vocabularies by a process of accepting or rejecting matches, assigning to each pair a "degree of belief".
The paper is presented succinctly and is to the point.</p>

<h3>Unit 6: Working Together</h3>
<p><b>Unit 6 Reading</b></p>
<p><a href="#finin_et_al">Finin et al (1994)</a> describes Knowledge Query and Manipulation Language (KQML). <a href="#searle">Searle</a>'s 
"speech acts" from Unit 5 reappear as "performatives." 
Messages containing both these instructions and data, for example in JSON format, can be exchanged between agents.
This is needed because of the emergence of a "large number of autonomous nodes" as the computing world was described in 1994, 
but reading this made me think of the APIs I have been writing, which use HTTP requests and responses in a similar way to KQML.
In fact I see no reason why HTTP cannot be a vehicle for KQML. On page 458 I see the authors got there before me.
The language is described in later pages, including a useful list of performatives.
This seems to have been a seminal paper on Agent Control Languages.
</p>

<p><b>Creating Agent Dialogues</b></p>
<p>The following messages use the Knowledge Query and Manipulation Language (KQML) <i>request</i> and <i>inform</i> performatives (<a href="#finin_et_al">Finin et al, 1994</a>).</p>
<p>Knowledge Interchange Format (KIF) keywords such as <i>ask-one</i> and <i>and</i> are listed in <a href="#genesereth">Genesereth (1992)</a>.</p>
<p>
<pre>
<b>Request number of 50 inch TVs in stock</b>
(request
  :sender agentAlice
  :receiver agentBob
  :ontology stock
  :language KIF
  :content
  (ask-one
    (and
      (in-stock ?item-name ?quantity)
      (equal ?item-name (TV :screen-size 50)))
  )
)

<b>Response</b>
(inform
  :sender agentBob
  :receiver agentAlice
  :ontology stock
  :language KIF
  :content
  (and
    (in-stock (TV :screen-size 50) 10)
  )
)

<b>Request number of HDMI ports</b>
(request
  :sender agentAlice
  :receiver agentBob
  :ontology stock
  :language KIF
  :content
  (ask-one
    (and
      (has-property ?item-name ?property ?value)
      (equal ?item-name (TV :screen-size 50))
      (equal ?property HDMI-slots))
  )
)

<b>Response</b>
(inform
  :sender agentBob
  :receiver agentAlice
  :ontology stock
  :language KIF
  :content
  (and
    (has-property (TV :screen-size 50) HDMI-slots 2)
  )
)
</pre>
</p>

<h3>Unit 7: Natural Language Processing (NLP)</h3>
<p><b>Unit 7 Lecturecast</b></p>
<p>The grammar and semantics of spoken/written languages are discussed, and natural language processing introduced as computers' methods of understanding them.
The concepts of syntax, semantics and pragmatics are compared in their natural language and computer contexts.
Problems such as ambiguity, vagueness and polysemy are described, and the role of statistical analysis of word distributions.
Systems like Word2Vec are introduced, with some Python code. 
Finally we get definitions of Hearst Patterns, hyponyms and types of parsing.
</p>
<p><b>Unit 7 Reading</b></p>
<p><a href="#mikolov">Mikolov (2013)</a> describes methods of collecting groups of words to build the vectors that were introduced in the lecturecast,
in particular a novel one called "skip-gram," which has the computational advantage of not multiplying matrices.
Shortcuts include the representation of whole phrases as vectors and the use of the softmax function 
to convert these vectors into probability distributions, sped up using a binary tree structure.
The authors describe their method of representing frequent words by a process of "negative sampling."
The vector addition of phrases promises to be a powerful tool in the comprehension of language by computers.</p>
<p><a href="#hearst">Hearst (2000)</a> shows how simple phrases such as "such as" or "a kind of" can reveal relationships between entities so that hyponyms can be learned.
The process is given a kick-start by starting with dictionaries.
Further patterns are discovered by ingesting large quantiries of text.
The resulting relations are fed into WordNet, a machine theaurus.</p>
<p><a href="#aqab">Aqab (2020)</a> promotes neural networks as the most efficient way of teaching machines to recognise handwriting,
where the demand is driven by the need to process cheques etc., and the potential for systems that can type up students' notes.
The method described in this paper consists of Python code learning from a set of characters found on Kaggle.  
This is a similar project to the Object Recognition assignment in the Machine Learning module.
</p>

<h3>Unit 8: Understanding Natural Language Processing (NLP)</h3>
<p><b>Unit 8 Reading</b></p>
<p><a href="#zimmerman">Zimmerman (2019)</a> Is about the tree-like representation of paresed phrases and sentences. 
The author shows how parsing can start with a list of words in the same order as the phrase or sentence, showing parts of speech and their functions, 
e.g. nsubj (subject) or amod (adjective).
Then this can be laid out in the same order but with connecting arrows showing these functions and the direction of modifications like adjectives.
A third way is shown, in a hierarchical order with the verb at the root, like a German sentence (ending with a verb) rotated 90&deg; anticlockwise.
The article describes how the spaCy NLP library for Python parses natural language into nodes, the tokens, and edges, "the syntactical relationships between the words."
The paper has links to:</p>
<ul>
<li><a href="https://spacy.io/">spaCy</a> Industrial-Strength Natural Language Processing in Python</li>
<li><a href="https://spacy.io/api/data-formats#pos-tagging">Data formats</a> Details on spaCy's input and output data formats</li>
<li><a href="https://www.youtube.com/watch?v=e12danHhlic">Yoav Goldberg: The missing elements in NLP (spaCy IRL 2019)</a></li>
</ul>

<h3>Unit 9: Introduction to Adaptive Algorithms</h3>
<p><b>Unit 9 Lecturecast</b></p>
<p>This lecturecast introduced artificial neural networks and discussed their basic structure, including layers for inputs and outputs, 
with hidden layers in between. Feature engineering, training and testing are very briefly mentioned, and then the example of handwriting recognition
is discussed.  Deep learning is described as a process which uses the neural network to engineer features as well as train on them,
and convolutional neural networks are introduced, having matrixes which can reduce the volume of data or recognise features.
We used CNNs to classify images in the Machine Learning module, but here the emphasis is on character recognition.</p>
<p><b>Unit 9 Reading</b></p>
<p>Unfortunately, both of this week's YouTube videos are unavailable, one "being reprocessed" and the other "private."</p>
<p>I searched for Andrew Ng on YouTube and found a course on Machine Learning (<a href="#ng">Ng, 2022</a>), 
which had apparently been on Coursera. Unfortunately, this did not go as far as deep learning.</p>
<p>A more relevant YouTube course was by a Qatar University professor (<a href="#elsayed">Elsayed, 2024</a>) and this introduced the concept well.</p>
<p><a href="#thomsen">Thomsen (Feb 19, 2015)</a> is very dubious about deep learning, or at least the perception of it as the path to self-aware computers.
He seems to dismiss image recognition as a party trick. His background is that he writes about "tech, video games, science and culture."</p>

<h3>Unit 10: Deep Learning in Action</h3>
<p><b>Unit 10 Reading</b></p>
<p>The article on deep learning's effect on business (<a href="#wef">WEF, 2022</a>) talks about the non-linearity of deep learning and how
this mimics the human brain's mode of operation. Uses are discussed, including "virtual assistants, fraud detection, language translation, 
chatbots and service bots, colourization of black-and-white images, facial recognition, disease diagnoses,... parsing speech,... autonomous vehicles."
The author has some concerns about the safety of devices that rely on deep learning, and the difficulty of troubleshooting systems that were
never actually programmed by anyone. The article ends by stating that 99% of data is not being used by deep learning systems.</p>

<h3>Unit 11: Intelligent Agents in Action</h3>

<h3>Unit 12: The Future of Intelligent Agents</h3>

<h3>References</h3>
<p id="aqab">Aqab, S. &amp; Tariq, M.U. (2020) Handwriting Recognition using Artificial Intelligence Neural Network and Image Processing. <i>(IJACSA) International Journal of Advanced Computer Science and Applications</i> 11(7): 137-146</p>
<p id="asimov">Asimov, I. (1942) Runaround. <i>Astounding Science Fiction</i> (March, 1942). New York: Street &amp; Smith Publications.</p>
<p id="bratman">Bratman, M.E., Israel, D.J. &amp; Pollack, M.E. (1988) Plans and resource-bounded practical reasoning. <i>Computational Intelligence</i> 4(3) 349-355. DOI: <a href="https://doi.org/10.1111/j.1467-8640.1988.tb00284.x">https://doi.org/10.1111/j.1467-8640.1988.tb00284.x</a></p>
<p id="brooks">Brooks, R. (1991) Intelligence without representation. <i>Artificial Intelligence</i> 47(1-3): 139-159. DOI: <a href="https://doi.org/10.1016/0004-3702(91)90053-M">https://doi.org/10.1016/0004-3702(91)90053-M</a></p>
<p id="cawsey">Cawsey, A. (1998) <i>The Essence of Artificial Intelligence</i>. Harlow: Pearson Education.</p>
<p id="elsayed">Elsayed, T. (2024) Deep Learning Fall 2024 Qatar University. Available from: <a href="https://www.youtube.com/playlist?list=PLRdABJkXXytCz19PsZ1PCQBKoZGV069k3">https://www.youtube.com/playlist?list=PLRdABJkXXytCz19PsZ1PCQBKoZGV069k3</a> [Accessed 3 October 2024].</p>
<p id="finin_et_al">Finin, T., Fritzson, R., McKay, D. &amp; McEntire, R. (1994) KQML as an agent communication language. <i>Proceedings of the third international conference on Information and knowledge management</i>: 456-463. DOI: <a href="https://doi.org/10.1145/191246.191322">https://doi.org/10.1145/191246.191322</a></p>
<p id="genesereth">Genesereth, M.R. et al (1992) Knowledge Interchange Format Version 3.0 Reference Manual. <i>Logic</i> 92(1).</p>
<p id="gilbert">Gilbert, N. (2020) <i>Agent-Based Models</i>. 2nd ed. Thousand Oaks: SAGE Publications.</p>
<p id="goertzel">Goertzel, B., &amp; Pennachin, C. (Eds.). (2007). <i>Artificial General Intelligence</i>. Berlin: Springer.</p>
<p id="hearst">Hearst, M.A. (2000) Automatic acquisition of hyponyms from large text corpora. <i>COLING '92: Proceedings of the 14th conference on Computational linguistics</i> 2: 539-545. DOI: <a href="https://doi.org/10.3115/992133.992154">https://dl.acm.org/doi/10.3115/992133.992154</a></p>
<p id="kaelbling">Kaelbling, L.P. (1991) A situated-automata approach to the design of embedded agents. <i>ACM SIGART Bulletin</i> 2(4): 85 - 88. DOI: <a href="https://doi.org/10.1145/122344.122361">https://doi.org/10.1145/122344.122361</a></p>
<p id="langton">Langton, C.G. (1995) <i>Artificial Life: An Overview</i>. Cambridge, MA: MIT Press.</p>
<p id="lee">Lee, Siu-Fan (2017) <i>Logic: A Complete Introduction</i>. London: Hodder Education.</p>
<p id="maes">Maes, P. (1991) The agent network architecture. <i>ACM SIGART Bulletin</i> 2(4): 115-120. DOI: <a href="https://doi.org/10.1145/122344.122367">https://doi.org/10.1145/122344.122367</a></p>
<p id="mikolov">Mikolov, T. et al. (2013) Distributed representations of words and phrases and their compositionality. <i>Advances in neural information processing systems</i>. Available from: <a href="https://proceedings.neurips.cc/paper_files/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf</a> [Accessed 21 September 2024].</p>
<p id="ng">Ng, A. (2022) Machine Learning YouTube course. Available from: <a href="https://www.youtube.com/playlist?list=PLkDaE6sCZn6FNC6YRfRQc_FbeQrF8BwGI">https://www.youtube.com/playlist?list=PLkDaE6sCZn6FNC6YRfRQc_FbeQrF8BwGI</a> [Accessed 3 October 2024].</p>
<p id="payne">Payne, T.R. &amp; Tamma, V. (2014) Negotiating over ontological correspondences with asymmetric and incomplete knowledge. <i>AAMAS '14: Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems</i> Sorbonne University, Paris, 5-9 May. 517-524.</p>
<p id="reynolds">Reynolds, C.W. (1987) Flocks, Herds, and Schools: A Distributed Behavioral Model. <i>Computer Graphics</i> 21(4): 25-34. DOI: <a href="https://doi.org/10.1145/37402.37406">https://doi.org/10.1145/37402.37406</a></p>
<p id="russell">Russell, S. &amp; Norvig, P. (2022) <i>Artificial Intelligence: A Modern Approach</i>. 4th ed. Harlow: Pearson Education.</p>
<p id="searle">Searle, J.R. (1969) <i>Speech Acts: An Essay in the Philosophy of Language</i>. Cambridge University Press. DOI: <a href="https://doi.org/10.1017/CBO9781139173438">https://doi.org/10.1017/CBO9781139173438</a></p>
<p id="testfatsion">Testfatsion, L &amp; Judd, K. (2006) 'Handbook of Computational Economics, Vol. 2: Agent-Based Computational Economics', in: Amman, H.M, Kendrick, D.A &amp; Rust, J. (eds) <i>Handbook of Computational Economics</i>. Amsterdam: Elsevier.</p>
<p id="thomsen">Thomsen, M. (Feb 19, 2015) Microsoft's Deep Learning Project Outperforms Humans in Image Recognition. <i>Forbes</i>. Available from: <a href="https://www.forbes.com/sites/michaelthomsen/2015/02/19/microsofts-deep-learning-project-outperforms-humans-in-image-recognition/">https://www.forbes.com/sites/michaelthomsen/2015/02/19/microsofts-deep-learning-project-outperforms-humans-in-image-recognition/</a> [Accessed 28 September 2024].</p>
<p id="viljoen">Viljoen, G. (2024) Initial Post to Collaborative Discussion 1: Agent Based Systems. Available from: <a href="https://www.my-course.co.uk/mod/forum/discuss.php?d=245817">www.my-course.co.uk/mod/forum/discuss.php?d=245817</a> [Accessed 13 August 2024].</p>
<p id="wef">WEF. (2022) How deep learning can improve productivity and boost business. <i>The Davos Agenda</i>. Available from: <a href="https://www.weforum.org/agenda/2022/01/deep-learning-business-productivity-revenue/">https://www.weforum.org/agenda/2022/01/deep-learning-business-productivity-revenue/</a> [Accessed 3 October 2024].</p>
<p id="wittgenstein">Wittgenstein, L. (1953) <i>Philosophical Investigations</i>. Oxford: Blackwell.</p>
<p id="wooldridge">Wooldridge, M.J. (2009) <i>An Introduction to Multiagent Systems</i>. Chichester: John Wiley &amp; Sons.</p>
<p id="zimmerman">Zimmerman, A. (2019) Getting to grips with parse trees. Available from: <a href="https://towardsdatascience.com/getting-to-grips-with-parse-trees-6e19e7cd3c3c">https://towardsdatascience.com/getting-to-grips-with-parse-trees-6e19e7cd3c3c</a> [Accessed 21 September 2024].</p>
<p>&nbsp;</p>
<p>Microsoft Word&trade; is a registered trademark of Microsoft Corporation.</p>
<p>&nbsp;</p>
</body>
</html>